{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 test samples: 100\n",
      "Common samples: 44\n",
      "Remaining samples: 56\n",
      "Still common samples: 0\n"
     ]
    }
   ],
   "source": [
    "test23 = read_file(\"data/NewsEmp2023/WASSA23_essay_level_test.tsv\")\n",
    "dev24 = read_file(\"data/NewsEmp2024/trac3_EMP_dev.csv\")\n",
    "print(f\"2023 test samples: {len(test23)}\")\n",
    "common_samples = set(test23[\"essay\"]).intersection(set(dev24[\"essay\"]))\n",
    "print(f\"Common samples: {len(common_samples)}\")\n",
    "remaining_samples = test23[~test23[\"essay\"].isin(common_samples)]\n",
    "print(f\"Remaining samples: {len(remaining_samples)}\")\n",
    "\n",
    "# Being super sure there is no overlap\n",
    "first_n_char = 25\n",
    "still_common = set(sample[:first_n_char] for sample in remaining_samples[\"essay\"]).intersection(set(sample[:first_n_char] for sample in dev24[\"essay\"]))\n",
    "print(f\"Still common samples: {len(still_common)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['conversation_id', 'article_id', 'essay', 'speaker_id', 'gender',\n",
       "       'education', 'race', 'age', 'income', 'speaker_number', 'split',\n",
       "       'essay_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test23.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_diff(file_tsv, n=10):\n",
    "    df = pd.read_csv(file_tsv, sep=\"\\t\")\n",
    "    df[\"diff\"] = df[\"empathy\"] - df[\"llm_empathy\"]\n",
    "    df[\"diff\"] = df[\"diff\"].abs()\n",
    "    df = df.sort_values(by=\"diff\", ascending=False)\n",
    "    print(df.head(n))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     conversation_id  article_id person_id  \\\n",
      "487              488         395      p031   \n",
      "594               95         233      p038   \n",
      "940              441           7      p022   \n",
      "981              482         292      p031   \n",
      "393              394         270      p010   \n",
      "860              361         163      p022   \n",
      "472              473         297      p024   \n",
      "91                92         233      p022   \n",
      "825              326          89      p024   \n",
      "4                  5          35      p022   \n",
      "\n",
      "                                                 essay   empathy  \\\n",
      "487  This is so sad and tragic. The most selfish th...  7.000000   \n",
      "594  This is sad. So many young women just used by ...  1.000000   \n",
      "940  After reading the article, my heart just break...  1.000000   \n",
      "981  It's amazing that people still debate the issu...  7.000000   \n",
      "393  I read the article on the China mining disaste...  7.000000   \n",
      "860  I feel really bad for the girl that lost her e...  1.000000   \n",
      "472  Anytime a train or car crash happens you start...  6.142857   \n",
      "91   What happened in the article was very upsettin...  1.000000   \n",
      "825  When crimes like this happened it is always go...  6.000000   \n",
      "4    After reading the article, you can't help but ...  1.000000   \n",
      "\n",
      "     person_distress  llm_empathy      diff  \n",
      "487         7.000000     1.333333  5.666667  \n",
      "594         1.000000     6.450000  5.450000  \n",
      "940         1.857143     6.383333  5.383333  \n",
      "981         7.000000     1.666667  5.333333  \n",
      "393         6.142857     1.833333  5.166667  \n",
      "860         1.714286     6.150000  5.150000  \n",
      "472         5.857143     1.000000  5.142857  \n",
      "91          1.714286     6.000000  5.000000  \n",
      "825         6.000000     1.000000  5.000000  \n",
      "4           1.428571     5.916667  4.916667  \n"
     ]
    }
   ],
   "source": [
    "df = get_top_diff(\"data/NewsEmp2024/trac3_EMP_train_llama.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I read the article on the China mining disaster.   There were 33 miners trapped in the mine.  Only two of them survived.  Officials stated whoever was responsible would be punished.   Smaller mines were shut down immediately until further notice.   China has always been known for the deadliest mining.  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[393, \"essay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     conversation_id  article_id person_id  \\\n",
      "393              394         270      p010   \n",
      "981              482         292      p031   \n",
      "940              441           7      p022   \n",
      "487              488         395      p031   \n",
      "904              405          92      p022   \n",
      "825              326          89      p024   \n",
      "91                92         233      p022   \n",
      "860              361         163      p022   \n",
      "998              499         103      p068   \n",
      "263              264          34      p022   \n",
      "\n",
      "                                                 essay  empathy  \\\n",
      "393  I read the article on the China mining disaste...      7.0   \n",
      "981  It's amazing that people still debate the issu...      7.0   \n",
      "940  After reading the article, my heart just break...      1.0   \n",
      "487  This is so sad and tragic. The most selfish th...      7.0   \n",
      "904  After reading the article, you just can't help...      1.0   \n",
      "825  When crimes like this happened it is always go...      6.0   \n",
      "91   What happened in the article was very upsettin...      1.0   \n",
      "860  I feel really bad for the girl that lost her e...      1.0   \n",
      "998  Everything about Russia really freaks me out. ...      6.0   \n",
      "263  My overall reaction is that i felt really bad ...      1.0   \n",
      "\n",
      "     person_distress  llm_empathy      diff  \n",
      "393         6.142857     1.666667  5.333333  \n",
      "981         7.000000     1.833333  5.166667  \n",
      "940         1.857143     6.083333  5.083333  \n",
      "487         7.000000     2.000000  5.000000  \n",
      "904         1.571429     5.833333  4.833333  \n",
      "825         6.000000     1.166667  4.833333  \n",
      "91          1.714286     5.833333  4.833333  \n",
      "860         1.714286     5.833333  4.833333  \n",
      "998         6.000000     1.166667  4.833333  \n",
      "263         1.428571     5.833333  4.833333  \n"
     ]
    }
   ],
   "source": [
    "df = get_top_diff(\"data/NewsEmp2024/trac3_EMP_train_gpt.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency of LLM Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from src.utils import read_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_consistency() -> pd.DataFrame:\n",
    "    tr_24 = pd.read_csv(\"data/NewsEmp2024/trac3_EMP_train_llama.tsv\", sep=\"\\t\")\n",
    "    tr_23 = pd.read_csv(\"data/NewsEmp2023/WASSA23_essay_level_with_labels_train_llama.tsv\", sep=\"\\t\")\n",
    "    dv_23 = pd.read_csv(\"data/NewsEmp2023/WASSA23_essay_level_dev_llama.tsv\", sep=\"\\t\")\n",
    "\n",
    "    print(tr_24.shape, tr_23.shape, dv_23.shape)\n",
    "\n",
    "    common_cols = tr_23.columns.intersection(dv_23.columns)\n",
    "    tr_23 = tr_23[common_cols]\n",
    "    dv_23 = dv_23[common_cols]\n",
    "    tr_dv_23 = pd.concat([tr_23, dv_23], ignore_index=True)\n",
    "    print(tr_dv_23.shape)\n",
    "\n",
    "    tr_24 = tr_24.drop_duplicates(subset=[\"essay\"])\n",
    "    tr_dv_23 = tr_dv_23.drop_duplicates(subset=[\"essay\"])\n",
    "    print(tr_24.shape, tr_dv_23.shape)\n",
    "\n",
    "    tr_24 = tr_24.rename(columns={\"llm_empathy\": \"llm_empathy_1\"})\n",
    "    tr_dv_23 = tr_dv_23.rename(columns={\"llm_empathy\": \"llm_empathy_2\"})\n",
    "\n",
    "    merged_df = pd.merge(tr_24, tr_dv_23, on=\"essay\", how=\"inner\", validate=\"one_to_one\")\n",
    "\n",
    "    common_cols = tr_24.columns.intersection(tr_dv_23.columns)\n",
    "    for col in common_cols:\n",
    "        if col == \"essay\":\n",
    "            continue\n",
    "\n",
    "        if merged_df[col + \"_x\"].equals(merged_df[col + \"_y\"]):\n",
    "            print(f\"{col} is equal\")\n",
    "            merged_df.drop(col + \"_y\", axis=1, inplace=True)\n",
    "            merged_df.rename(columns={col + \"_x\": col}, inplace=True)\n",
    "        else:\n",
    "            print(f\"{col} is not equal\")\n",
    "\n",
    "    llm_empathy_1 = torch.tensor(merged_df[\"llm_empathy_1\"].values)\n",
    "    llm_empathy_2 = torch.tensor(merged_df[\"llm_empathy_2\"].values)\n",
    "\n",
    "    pcc = pearson_corrcoef(llm_empathy_1, llm_empathy_2).item()\n",
    "    ccc = concordance_corrcoef(llm_empathy_1, llm_empathy_2).item()\n",
    "    rmse = mean_squared_error(llm_empathy_1, llm_empathy_2, squared=False).item()\n",
    "    pcc = round(pcc, 3)\n",
    "    ccc = round(ccc, 3)\n",
    "    rmse = round(rmse, 3)\n",
    "\n",
    "    print(f\"PCC: {pcc}, CCC: {ccc}, RMSE: {rmse}\")\n",
    "\n",
    "    merged_df[\"llm_diff\"] = np.abs(merged_df[\"llm_empathy_1\"] - merged_df[\"llm_empathy_2\"])\n",
    "    mean_diff = merged_df[\"llm_diff\"].mean().round(3)\n",
    "    std_diff = merged_df[\"llm_diff\"].std().round(3)\n",
    "    print(f\"Difference - Mean: {mean_diff}, Std: {std_diff}\")\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = read_file(\"data/NewsEmp2024/trac3_EMP_train_gpt.tsv\")\n",
    "llama = read_file(\"data/NewsEmp2024/trac3_EMP_train_llama.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr23 = read_file(\"data/NewsEmp2023/WASSA23_essay_level_with_labels_train_llama.tsv\")\n",
    "dv23 = read_file(\"data/NewsEmp2023/WASSA23_essay_level_dev_llama.tsv\")\n",
    "tr24 = read_file(\"data/NewsEmp2024/trac3_EMP_train_llama.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_col = set(tr23.columns).intersection(set(dv23.columns))\n",
    "tr23 = tr23[list(common_col)]\n",
    "dv23 = dv23[list(common_col)]\n",
    "intra1 = pd.concat([tr23, dv23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra1 = intra1.rename(columns={\"llm_empathy\": \"llm_empathy_1\"})\n",
    "tr24 = tr24.rename(columns={\"llm_empathy\": \"llm_empathy_2\"})\n",
    "\n",
    "merged_df = pd.merge(intra1, tr24, on=\"essay\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _measure_consistency(x, y):\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    kr_alpha =  krippendorff.alpha((x, y), level_of_measurement=\"interval\")\n",
    "    mean_diff = mean_absolute_error(x, y)\n",
    "    std = np.std(np.abs(x - y))\n",
    "\n",
    "    scores = {\n",
    "        \"kr_alpha\": kr_alpha,\n",
    "        \"mean_diff\": mean_diff,\n",
    "        \"std\": std,\n",
    "    }\n",
    "    print(scores)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kr_alpha': 0.9911124565274333, 'mean_diff': 0.10303030303030304, 'std': 0.20653715145300666}\n"
     ]
    }
   ],
   "source": [
    "_measure_consistency(merged_df[\"llm_empathy_1\"], merged_df[\"llm_empathy_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kr_alpha': 0.27089326729430385, 'mean_diff': 1.7153761904761904, 'std': 1.3416888117410164}\n",
      "{'kr_alpha': 0.19190195858747383, 'mean_diff': 1.8091785714285715, 'std': 1.2709864220828826}\n",
      "{'kr_alpha': 0.7960720891694217, 'mean_diff': 0.7848166666666667, 'std': 0.7025072318726217}\n"
     ]
    }
   ],
   "source": [
    "# Inter-LLM consistency\n",
    "_measure_consistency(llama[\"empathy\"], llama[\"llm_empathy\"])\n",
    "_measure_consistency(gpt[\"empathy\"], gpt[\"llm_empathy\"])\n",
    "_measure_consistency(gpt[\"llm_empathy\"], llama[\"llm_empathy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
