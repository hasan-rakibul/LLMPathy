############ NOT used if any load_from_checkpoint is provided #######

# expt_name: Baseline
# expt_name: DetectNoiseLabels_Agentic_v2_v3
# expt_name: DetectNoiseLabels_Agentic_Onlyv3
# expt_name: DetectNoiseLabels_Agentic_Onlyv3
expt_name: Tune_Agentic

############ Used for most of the experiments ############

seed: 0
num_workers: 12
plm: roberta-base
num_epochs: 10
lr: 1.0e-5
batch_size: 16
logging_dir: ./logs

test_mode: False # training and validation only
load_from_checkpoint: False # False or path to checkpoint file (.ckpt) of the vanilla model (not the agentic models)

# test_mode: True # only for testing
save_predictions_to_disk: True # True or False
# load_from_checkpoint: logs/20240920_164626_Baseline/lightning_logs/version_15755097/checkpoints/epoch=6-step=147.ckpt

save_agentics_to_disk: False # True or False

# train_file_list: ["data/NewsEmp2022/messages_train_ready_for_WS_with_LLM.tsv", "./data/NewsEmp2023/WASSA23_essay_level_with_labels_train_with_LLM.tsv"]

label_column: empathy
llm_column: llm_empathy

val_file_list: ["data/NewsEmp2023/WASSA23_essay_level_dev.tsv"]

### for 2022 and 2023, we have separate gold standard files
val_goldstandard_file: data/NewsEmp2023/goldstandard_dev.tsv

test_file_list: ["data/NewsEmp2023/WASSA23_essay_level_test.tsv"]

############ v2 only ############


############ v3 only ############
train_file_list: ["./data/NewsEmp2023/WASSA23_essay_level_with_labels_train_with_LLM.tsv"]

feature_to_tokenise: ["essay"]

### extra column in train, val and test
# extra_columns_to_keep: ["article_id"]
extra_columns_to_keep: []

### extra column in train only
extra_columns_to_keep_train: ["llm_empathy"]

max_length: 512
demographics: []
# demographics: ['gender', 'education', 'race', 'age', 'income']

############ For Agentic approach ############
noise_level: 0.5
num_agents: 5

# updated_train_dl_file: False
updated_train_dl_file: logs/20240926_113249_DetectNoiseLabels_Agentic_v2_v3/updated_train_dl.pt

########## Optuna ##########
n_optuna_trails: 100
resume_optuna_dir: False
