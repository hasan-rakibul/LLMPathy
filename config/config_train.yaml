############ NOT used if any load_from_checkpoint or updated_train_dl_file is provided #######

debug_mode: False 

expt_name: Baseline-Demographics-TrainedWith2023
# expt_name: DetectNoiseLabels_Agentic_v2_v3
# expt_name: Agentic_Onlyv3_Strict-EarlyStopping

val_only: False

############ Used for most of the experiments ############

seed: 0
num_workers: 12
plm: roberta-base
num_epochs: 10
lr: 1.0e-5
batch_size: 16
logging_dir: ./logs
fc_arch: [768, 512, 256, 1] # [out_transforer, out_pre_fusion, out_fusion, out]

load_from_checkpoint: False # False or path to checkpoint file (.ckpt) of the vanilla model (not the agentic models)
# load_from_checkpoint: logs/20241003_065520_Baseline-TrainedWith2023/lightning_logs/version_16421343/checkpoints/epoch=2-step=147.ckpt

save_predictions_to_disk: False # so that we don't save all val steps each epoch

label_column: empathy
llm_column: llm_empathy
feature_to_tokenise: ["essay"]
# extra_columns_to_keep: ["article_id"]
extra_columns_to_keep: []

### extra column in train only
extra_columns_to_keep_train: ["llm_empathy"]

max_length: 512
# demographics: []
demographics: ['gender', 'education', 'race', 'age', 'income']

updated_train_dl_file: False # if running baseline
# updated_train_dl_file: ./logs/20241003_113735_Agentic_Onlyv3/updated_train_dl.pt

############ 2022 and 2023 ############
# train_file_list: ["data/NewsEmp2022/messages_train_ready_for_WS_with_LLM.tsv", "./data/NewsEmp2023/WASSA23_essay_level_with_labels_train_with_LLM.tsv"]

### for 2022 and 2023, we have separate gold standard files

############ 2022 ############


############ 2023 ############
train_file_list: ["./data/NewsEmp2023/WASSA23_essay_level_with_labels_train_with_LLM.tsv"]
val_file_list: ["data/NewsEmp2023/WASSA23_essay_level_dev.tsv"]
val_goldstandard_file: data/NewsEmp2023/goldstandard_dev.tsv
